{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgaCgQoXPvbp"
      },
      "source": [
        "# 라이브러리 및 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpKn-baaPUit"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import function libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "import os, sys ,math, copy\n",
        "import scipy.io as sio\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.engine import Layer, InputSpec\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "\n",
        "sys.setrecursionlimit(10000)\n",
        "\n",
        "\n",
        "train_sample = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/train.csv\", header=0, encoding='utf-8')\n",
        "path = r'/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2'\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "# count the number of pass/fail items\n",
        "\n",
        "train_sample_np = np.array(train_sample.copy())\n",
        "\n",
        "\n",
        "# load csv file\n",
        "li_df = []\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)    \n",
        "    li_df.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "bNQQ9ABWPb_R",
        "outputId": "534c3f56-3699-42a2-d52b-20f10dc88810"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>material</th>\n",
              "      <th>feedrate</th>\n",
              "      <th>clamp_pressure</th>\n",
              "      <th>tool_condition</th>\n",
              "      <th>machining_finalized</th>\n",
              "      <th>passed_visual_inspection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>20</td>\n",
              "      <td>4.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>6</td>\n",
              "      <td>2.5</td>\n",
              "      <td>unworn</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>20</td>\n",
              "      <td>3.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>20</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>20</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>15</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>12</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>20</td>\n",
              "      <td>3.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>15</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>12</td>\n",
              "      <td>4.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>20</td>\n",
              "      <td>3.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>worn</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>unworn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>aluminum</td>\n",
              "      <td>6</td>\n",
              "      <td>2.5</td>\n",
              "      <td>worn</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    No  material  ...  machining_finalized  passed_visual_inspection\n",
              "0    1  aluminum  ...                  yes                       yes\n",
              "1    2  aluminum  ...                  yes                       yes\n",
              "2    3  aluminum  ...                  yes                       yes\n",
              "3    4  aluminum  ...                   no                       NaN\n",
              "4    5  aluminum  ...                   no                       NaN\n",
              "5    6  aluminum  ...                  yes                        no\n",
              "6    7  aluminum  ...                   no                       NaN\n",
              "7    8  aluminum  ...                  yes                        no\n",
              "8    9  aluminum  ...                  yes                        no\n",
              "9   10  aluminum  ...                  yes                        no\n",
              "10  11  aluminum  ...                  yes                       yes\n",
              "11  12  aluminum  ...                  yes                       yes\n",
              "12  13  aluminum  ...                  yes                       yes\n",
              "13  14  aluminum  ...                  yes                       yes\n",
              "14  15  aluminum  ...                  yes                       yes\n",
              "15  16  aluminum  ...                   no                       NaN\n",
              "16  17  aluminum  ...                  yes                       yes\n",
              "17  18  aluminum  ...                  yes                       yes\n",
              "18  19  aluminum  ...                  yes                        no\n",
              "19  20  aluminum  ...                   no                       NaN\n",
              "20  21  aluminum  ...                  yes                        no\n",
              "21  22  aluminum  ...                  yes                       yes\n",
              "22  23  aluminum  ...                   no                       NaN\n",
              "23  24  aluminum  ...                  yes                       yes\n",
              "24  25  aluminum  ...                  yes                       yes\n",
              "\n",
              "[25 rows x 7 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sample # 전체 실험 샘플의 데이터 - 각 25번의 실험의 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "lb0TPXLSK4Le",
        "outputId": "ff36ff88-a90a-48e4-a312-2838ac249711"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_ActualPosition</th>\n",
              "      <th>X_ActualVelocity</th>\n",
              "      <th>X_ActualAcceleration</th>\n",
              "      <th>X_SetPosition</th>\n",
              "      <th>X_SetVelocity</th>\n",
              "      <th>X_SetAcceleration</th>\n",
              "      <th>X_CurrentFeedback</th>\n",
              "      <th>X_DCBusVoltage</th>\n",
              "      <th>X_OutputCurrent</th>\n",
              "      <th>X_OutputVoltage</th>\n",
              "      <th>X_OutputPower</th>\n",
              "      <th>Y_ActualPosition</th>\n",
              "      <th>Y_ActualVelocity</th>\n",
              "      <th>Y_ActualAcceleration</th>\n",
              "      <th>Y_SetPosition</th>\n",
              "      <th>Y_SetVelocity</th>\n",
              "      <th>Y_SetAcceleration</th>\n",
              "      <th>Y_CurrentFeedback</th>\n",
              "      <th>Y_DCBusVoltage</th>\n",
              "      <th>Y_OutputCurrent</th>\n",
              "      <th>Y_OutputVoltage</th>\n",
              "      <th>Y_OutputPower</th>\n",
              "      <th>Z_ActualPosition</th>\n",
              "      <th>Z_ActualVelocity</th>\n",
              "      <th>Z_ActualAcceleration</th>\n",
              "      <th>Z_SetPosition</th>\n",
              "      <th>Z_SetVelocity</th>\n",
              "      <th>Z_SetAcceleration</th>\n",
              "      <th>Z_CurrentFeedback</th>\n",
              "      <th>Z_DCBusVoltage</th>\n",
              "      <th>Z_OutputCurrent</th>\n",
              "      <th>Z_OutputVoltage</th>\n",
              "      <th>S_ActualPosition</th>\n",
              "      <th>S_ActualVelocity</th>\n",
              "      <th>S_ActualAcceleration</th>\n",
              "      <th>S_SetPosition</th>\n",
              "      <th>S_SetVelocity</th>\n",
              "      <th>S_SetAcceleration</th>\n",
              "      <th>S_CurrentFeedback</th>\n",
              "      <th>S_DCBusVoltage</th>\n",
              "      <th>S_OutputCurrent</th>\n",
              "      <th>S_OutputVoltage</th>\n",
              "      <th>S_OutputPower</th>\n",
              "      <th>S_SystemInertia</th>\n",
              "      <th>M_CURRENT_PROGRAM_NUMBER</th>\n",
              "      <th>M_sequence_number</th>\n",
              "      <th>M_CURRENT_FEEDRATE</th>\n",
              "      <th>Machining_Process</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>176.0</td>\n",
              "      <td>10.0500</td>\n",
              "      <td>57.000</td>\n",
              "      <td>176.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>-0.620</td>\n",
              "      <td>0.0194</td>\n",
              "      <td>327</td>\n",
              "      <td>0.709</td>\n",
              "      <td>-1.030000e-06</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.0125</td>\n",
              "      <td>10.250</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5610</td>\n",
              "      <td>0.0175</td>\n",
              "      <td>326</td>\n",
              "      <td>1.400</td>\n",
              "      <td>-0.000001</td>\n",
              "      <td>77.85</td>\n",
              "      <td>4.0125</td>\n",
              "      <td>10.250</td>\n",
              "      <td>77.85</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>30.649500</td>\n",
              "      <td>-10.400</td>\n",
              "      <td>119.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.444</td>\n",
              "      <td>2.760000e-19</td>\n",
              "      <td>327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.720000e-06</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>176.5</td>\n",
              "      <td>9.9500</td>\n",
              "      <td>-46.000</td>\n",
              "      <td>176.5</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>-0.779</td>\n",
              "      <td>0.0198</td>\n",
              "      <td>328</td>\n",
              "      <td>1.040</td>\n",
              "      <td>2.280000e-06</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.0125</td>\n",
              "      <td>10.250</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>326</td>\n",
              "      <td>0.144</td>\n",
              "      <td>-0.000001</td>\n",
              "      <td>77.85</td>\n",
              "      <td>3.9875</td>\n",
              "      <td>0.875</td>\n",
              "      <td>77.85</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>30.650500</td>\n",
              "      <td>8.560</td>\n",
              "      <td>124.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.400</td>\n",
              "      <td>2.760000e-19</td>\n",
              "      <td>328</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.770000e-07</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>177.0</td>\n",
              "      <td>10.1500</td>\n",
              "      <td>54.000</td>\n",
              "      <td>177.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.979</td>\n",
              "      <td>0.0192</td>\n",
              "      <td>327</td>\n",
              "      <td>2.620</td>\n",
              "      <td>1.150000e-06</td>\n",
              "      <td>135.50</td>\n",
              "      <td>3.9875</td>\n",
              "      <td>0.875</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5100</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>326</td>\n",
              "      <td>2.180</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>77.85</td>\n",
              "      <td>3.9875</td>\n",
              "      <td>0.875</td>\n",
              "      <td>77.85</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>30.700000</td>\n",
              "      <td>12.025</td>\n",
              "      <td>124.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.267</td>\n",
              "      <td>2.760000e-19</td>\n",
              "      <td>327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.780000e-07</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>177.5</td>\n",
              "      <td>9.9625</td>\n",
              "      <td>-30.350</td>\n",
              "      <td>177.5</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>-0.779</td>\n",
              "      <td>0.0179</td>\n",
              "      <td>327</td>\n",
              "      <td>1.840</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0251</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>326</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>77.85</td>\n",
              "      <td>3.9875</td>\n",
              "      <td>-2.250</td>\n",
              "      <td>77.85</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>30.650500</td>\n",
              "      <td>-23.400</td>\n",
              "      <td>129.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.443</td>\n",
              "      <td>2.760000e-19</td>\n",
              "      <td>327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>178.5</td>\n",
              "      <td>9.8375</td>\n",
              "      <td>-77.250</td>\n",
              "      <td>178.5</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>-1.260</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>328</td>\n",
              "      <td>1.350</td>\n",
              "      <td>2.560000e-07</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>7.125</td>\n",
              "      <td>135.50</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.0582</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>327</td>\n",
              "      <td>1.580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.85</td>\n",
              "      <td>3.9875</td>\n",
              "      <td>4.000</td>\n",
              "      <td>77.85</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>30.599125</td>\n",
              "      <td>-16.069</td>\n",
              "      <td>129.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.865</td>\n",
              "      <td>2.760000e-19</td>\n",
              "      <td>327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.070000e-06</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>154.0</td>\n",
              "      <td>9.9000</td>\n",
              "      <td>19.650</td>\n",
              "      <td>154.0</td>\n",
              "      <td>9.95</td>\n",
              "      <td>6.92</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.0226</td>\n",
              "      <td>327</td>\n",
              "      <td>2.220</td>\n",
              "      <td>-1.150000e-06</td>\n",
              "      <td>102.35</td>\n",
              "      <td>2.9500</td>\n",
              "      <td>4.000</td>\n",
              "      <td>102.35</td>\n",
              "      <td>3.07</td>\n",
              "      <td>21.9</td>\n",
              "      <td>-1.0200</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>326</td>\n",
              "      <td>2.350</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>55.20</td>\n",
              "      <td>28.9375</td>\n",
              "      <td>-5.375</td>\n",
              "      <td>55.40</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>384.0</td>\n",
              "      <td>30.650875</td>\n",
              "      <td>-0.466</td>\n",
              "      <td>384.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.332</td>\n",
              "      <td>2.770000e-19</td>\n",
              "      <td>326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>End</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>154.5</td>\n",
              "      <td>9.6500</td>\n",
              "      <td>22.750</td>\n",
              "      <td>154.5</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1.670</td>\n",
              "      <td>0.0268</td>\n",
              "      <td>327</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>102.30</td>\n",
              "      <td>3.9875</td>\n",
              "      <td>-2.250</td>\n",
              "      <td>102.30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>0.0228</td>\n",
              "      <td>325</td>\n",
              "      <td>3.800</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>57.70</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>16.500</td>\n",
              "      <td>57.90</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>30.750500</td>\n",
              "      <td>32.775</td>\n",
              "      <td>389.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.518</td>\n",
              "      <td>2.770000e-19</td>\n",
              "      <td>326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>End</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>155.0</td>\n",
              "      <td>9.8750</td>\n",
              "      <td>-64.600</td>\n",
              "      <td>155.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.544</td>\n",
              "      <td>0.0274</td>\n",
              "      <td>327</td>\n",
              "      <td>1.510</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>102.30</td>\n",
              "      <td>4.0500</td>\n",
              "      <td>29.000</td>\n",
              "      <td>102.30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.5300</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>325</td>\n",
              "      <td>1.370</td>\n",
              "      <td>-0.000006</td>\n",
              "      <td>60.15</td>\n",
              "      <td>28.9500</td>\n",
              "      <td>13.400</td>\n",
              "      <td>60.40</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>30.700500</td>\n",
              "      <td>17.300</td>\n",
              "      <td>389.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>2.770000e-19</td>\n",
              "      <td>327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.050000e-06</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>End</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>155.5</td>\n",
              "      <td>9.9500</td>\n",
              "      <td>-52.125</td>\n",
              "      <td>155.5</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1.100</td>\n",
              "      <td>0.0275</td>\n",
              "      <td>327</td>\n",
              "      <td>1.900</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>102.30</td>\n",
              "      <td>3.9625</td>\n",
              "      <td>-11.650</td>\n",
              "      <td>102.30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.0891</td>\n",
              "      <td>0.0169</td>\n",
              "      <td>325</td>\n",
              "      <td>3.720</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>62.70</td>\n",
              "      <td>29.0625</td>\n",
              "      <td>25.875</td>\n",
              "      <td>62.90</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>30.649125</td>\n",
              "      <td>2.686</td>\n",
              "      <td>394.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>2.770000e-19</td>\n",
              "      <td>326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.930000e-06</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>End</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>156.0</td>\n",
              "      <td>10.1000</td>\n",
              "      <td>76.125</td>\n",
              "      <td>156.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.507</td>\n",
              "      <td>0.0192</td>\n",
              "      <td>327</td>\n",
              "      <td>0.363</td>\n",
              "      <td>-1.250000e-06</td>\n",
              "      <td>102.30</td>\n",
              "      <td>3.9500</td>\n",
              "      <td>-17.875</td>\n",
              "      <td>102.30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.8890</td>\n",
              "      <td>0.0211</td>\n",
              "      <td>325</td>\n",
              "      <td>2.940</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>65.20</td>\n",
              "      <td>29.0250</td>\n",
              "      <td>10.250</td>\n",
              "      <td>65.40</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>30.750500</td>\n",
              "      <td>25.925</td>\n",
              "      <td>394.0</td>\n",
              "      <td>30.65</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.518</td>\n",
              "      <td>2.770000e-19</td>\n",
              "      <td>326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.410000e-06</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>End</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>462 rows × 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     X_ActualPosition  X_ActualVelocity  ...  M_CURRENT_FEEDRATE  Machining_Process\n",
              "0               176.0           10.0500  ...                   6               Prep\n",
              "1               176.5            9.9500  ...                   6               Prep\n",
              "2               177.0           10.1500  ...                   6               Prep\n",
              "3               177.5            9.9625  ...                   6               Prep\n",
              "4               178.5            9.8375  ...                   6               Prep\n",
              "..                ...               ...  ...                 ...                ...\n",
              "457             154.0            9.9000  ...                  50                End\n",
              "458             154.5            9.6500  ...                  50                End\n",
              "459             155.0            9.8750  ...                  50                End\n",
              "460             155.5            9.9500  ...                  50                End\n",
              "461             156.0           10.1000  ...                  50                End\n",
              "\n",
              "[462 rows x 48 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df # 각 실험 샘플의 상세 데이터 - 각 실험 샘플의 condition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGjVEJzKNZZI",
        "outputId": "2c45e598-a74c-4c99-fdfa-132b21dbb94f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_01.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_02.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_03.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_04.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_05.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_06.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_07.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_08.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_09.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_10.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_11.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_12.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_13.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_14.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_15.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_16.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_17.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_18.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_19.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_20.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_21.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_22.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_23.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_24.csv',\n",
              " '/content/drive/MyDrive/Colab Notebooks/제조프로젝트/dataset/CNC 비식별화 원본데이터_1209/CNC Virtual Data set _v2/experiment_25.csv']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_files.sort() \n",
        "all_files # 실험 순서에 맞게 실험 정렬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzGEvfDINmEG",
        "outputId": "d721f91c-9aff-4b0a-fb8e-5535bd34a93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "양품 샘플 개수:  13\n",
            "공정 완료했지만 육안검사를 통과하지 못한 샘플의 개수:  6\n",
            "공정을 완료하지 못한 샘플의 개수:  6\n",
            "전체 샘플의 개수:  25\n"
          ]
        }
      ],
      "source": [
        "nb_pass = 0 # 양품 샘플의 개수를 저장할 변수 선언\n",
        "nb_pass_half = 0 # 공정은 완료했으나 육안검사를 통과하지 못한 샘플의 개수 변수 선언\n",
        "nb_defective = 0 # 공정을 완료하지 못한 샘플의 개수 변수 선언\n",
        "for i in range(len(train_sample_np)): # 각 샘플에 대하여\n",
        "  if train_sample_np[i,5] == 'no': # 공정이 완료되지 않았으면\n",
        "    nb_defective += 1 # defective 개수에 1개 추가\n",
        "  if train_sample_np[i,5] == 'yes' and train_sample_np[i,6] == 'no': # 공정이 완료되었지만 육안검사를 통과하지 않았으면\n",
        "    nb_pass_half +=1 # half 개수에 1개 추가\n",
        "  if train_sample_np[i,5] == 'yes' and train_sample_np[i,6] == 'yes': # 공정도 완료되었고 육안검사도 통과했다면\n",
        "    nb_pass +=1 # pass 개수에 1 추가 \n",
        "\n",
        "print('양품 샘플 개수: ',nb_pass)\n",
        "print('공정 완료했지만 육안검사를 통과하지 못한 샘플의 개수: ',nb_pass_half)\n",
        "print('공정을 완료하지 못한 샘플의 개수: ',nb_defective)\n",
        "print('전체 샘플의 개수: ', nb_pass + nb_defective + nb_pass_half)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a2jIolraRnIh"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGP4YLNfRySo"
      },
      "outputs": [],
      "source": [
        "def tool_condition(input):\n",
        "    for i in range(len(input)):\n",
        "        if input[i,4] == 'unworn': # 공구가 마모되지 않았으면 \n",
        "            input[i,4] = 0\n",
        "        else:                      # 공구가 마모되었으면\n",
        "            input[i,4] = 1\n",
        "    return input\n",
        "\n",
        "def item_inspection(input): # 샘플의 공정 결과 분류\n",
        "    for i in range(len(input)):\n",
        "        if input[i,5] == 'no':      # 공정이 완료되지 않았으면\n",
        "            input[i,6] = 2\n",
        "        elif input[i,5] == 'yes' and input[i,6] == 'no': # 공정은 완료되었지만 육안검사를 통과하지 못했으면\n",
        "            input[i,6] = 1\n",
        "        elif input[i,5] == 'yes' and input[i,6] == 'yes': # 공정도 완료하고 육안검사도 통과한 양품이면\n",
        "            input[i,6] = 0\n",
        "    return input\n",
        "\n",
        "\n",
        "def machining_process(input): # 공정 상태에 대해서 0~9로 분류\n",
        "    for i in range(len(input)):\n",
        "        if input[i,47] == 'Prep':\n",
        "            input[i,47] = 0\n",
        "        elif input[i,47] == 'Layer 1 Up':\n",
        "            input[i,47] = 1\n",
        "        elif input[i,47] == 'Layer 1 Down':\n",
        "            input[i,47] = 2\n",
        "        elif input[i,47] == 'Layer 2 Up':\n",
        "            input[i,47] = 3\n",
        "        elif input[i,47] == 'Layer 2 Down':\n",
        "            input[i,47] = 4\n",
        "        elif input[i,47] == 'Layer 3 Up':\n",
        "            input[i,47] = 5\n",
        "        elif input[i,47] == 'Layer 3 Down':\n",
        "            input[i,47] = 6\n",
        "        elif input[i,47] == 'Repositioning':\n",
        "            input[i,47] = 7\n",
        "        elif input[i,47] == 'End' or 'end':\n",
        "            input[i,47] = 8        \n",
        "        elif input[i,47] == 'Starting':\n",
        "            input[i,47] = 9\n",
        "    return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZXaVWTqSaUo",
        "outputId": "fdfc59c6-cd10-4a50-c94b-e34ffd13b7f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6 4.0 0 0]\n",
            " [20 4.0 0 0]\n",
            " [6 3.0 0 0]\n",
            " [6 2.5 0 2]\n",
            " [20 3.0 0 2]\n",
            " [6 4.0 1 1]\n",
            " [20 4.0 1 2]\n",
            " [20 4.0 1 1]\n",
            " [15 4.0 1 1]\n",
            " [12 4.0 1 1]\n",
            " [3 4.0 0 0]\n",
            " [3 3.0 0 0]\n",
            " [3 4.0 1 0]\n",
            " [3 3.0 1 0]\n",
            " [6 3.0 1 0]\n",
            " [20 3.0 1 2]\n",
            " [3 2.5 0 0]\n",
            " [3 2.5 1 0]\n",
            " [15 4.0 1 1]\n",
            " [12 4.0 0 2]\n",
            " [3 4.0 0 1]\n",
            " [20 3.0 1 0]\n",
            " [3 4.0 1 2]\n",
            " [3 3.0 0 0]\n",
            " [6 2.5 1 0]]\n"
          ]
        }
      ],
      "source": [
        "# 공구 마모와 공정 결과 데이터 전처리\n",
        "train_sample_info = np.array(train_sample_np.copy())\n",
        "train_sample_info = tool_condition(train_sample_info)\n",
        "train_sample_info = item_inspection(train_sample_info)\n",
        "\n",
        "# 필요 없는 열 (재질, 순서 삭제)\n",
        "train_sample_info = np.delete(train_sample_info,5,1)\n",
        "train_sample_info = np.delete(train_sample_info,0,1)\n",
        "train_sample_info = np.delete(train_sample_info,0,1)\n",
        "print(train_sample_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLQSw4WSTlwd"
      },
      "source": [
        "# 학습에 사용할 샘플 데이터 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vju4dCWUaOT",
        "outputId": "d804854a-8f13-4803-9872-430d3ae368ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[6, 4.0, 0, 0],\n",
              "       [20, 4.0, 0, 0],\n",
              "       [6, 3.0, 0, 0],\n",
              "       [6, 2.5, 0, 2],\n",
              "       [20, 3.0, 0, 2],\n",
              "       [6, 4.0, 1, 1],\n",
              "       [20, 4.0, 1, 2],\n",
              "       [20, 4.0, 1, 1],\n",
              "       [15, 4.0, 1, 1],\n",
              "       [12, 4.0, 1, 1],\n",
              "       [3, 4.0, 0, 0],\n",
              "       [3, 3.0, 0, 0],\n",
              "       [3, 4.0, 1, 0],\n",
              "       [3, 3.0, 1, 0],\n",
              "       [6, 3.0, 1, 0],\n",
              "       [20, 3.0, 1, 2],\n",
              "       [3, 2.5, 0, 0],\n",
              "       [3, 2.5, 1, 0],\n",
              "       [15, 4.0, 1, 1],\n",
              "       [12, 4.0, 0, 2],\n",
              "       [3, 4.0, 0, 1],\n",
              "       [20, 3.0, 1, 0],\n",
              "       [3, 4.0, 1, 2],\n",
              "       [3, 3.0, 0, 0],\n",
              "       [6, 2.5, 1, 0]], dtype=object)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sample_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwNI3YLqTrqk",
        "outputId": "04ce8a5b-c5b8-4239-be5d-4a4dfc1462f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "공정완료 및 육안검사 합격한 전체 데이터의 수:  22645\n",
            "공정완료 및 육안검사 불합격한 전체 데이터의 수:  6175\n",
            "공정 미완료한 전체 데이터의 수:  3228\n"
          ]
        }
      ],
      "source": [
        "k = 0 # \n",
        "li_pass = []\n",
        "li_pass_half = []\n",
        "li_fail = []\n",
        "for file in all_files:\n",
        "  df= pd.read_csv(file, index_col=None, header = 0)\n",
        "                                      # 각 실험 파일들을 가져와서\n",
        "  if train_sample_info[k,3] == 0:     # 공정 결과에 따라\n",
        "    li_pass.append(df)                # 0 (공정 완료, 육안검사 통과) 에 분류\n",
        "  elif train_sample_info[k,3] == 1:   # 1 (공정 완료, 육안검사 못 통과)\n",
        "    li_pass_half.append(df)        \n",
        "  else :                              # 2 (공정 미완료)\n",
        "    li_fail.append(df)\n",
        "  k += 1\n",
        "\n",
        "# 분류된 상세 데이터들을 취합 (아래로 더해줌, 인덱스 무시 -> array로 바꾸기 위해)\n",
        "frame01 = pd.concat(li_pass, axis = 0, ignore_index= True)\n",
        "frame02 = pd.concat(li_pass_half, axis = 0, ignore_index= True)\n",
        "frame03 = pd.concat(li_fail, axis = 0 , ignore_index= True)\n",
        "# 상세 데이터를 array로 만듬\n",
        "data_pass = np.array(frame01.copy())\n",
        "data_pass_half = np.array(frame02.copy())\n",
        "data_fail = np.array(frame03.copy())\n",
        "\n",
        "print('공정완료 및 육안검사 합격한 전체 데이터의 수: ',len(data_pass))\n",
        "print('공정완료 및 육안검사 불합격한 전체 데이터의 수: ',len(data_pass_half))\n",
        "print('공정 미완료한 전체 데이터의 수: ',len(data_fail))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBAj-EyYYAqZ",
        "outputId": "d89e44f5-5147-4de4-f47d-f4c9146d7b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(22645, 48)\n",
            "(6175, 48)\n",
            "(3228, 48)\n"
          ]
        }
      ],
      "source": [
        "# 분류 데이터 사이즈 확인 -> 행:데이터 개수  열:독립변수 개수\n",
        "print(data_pass.shape)\n",
        "print(data_pass_half.shape)\n",
        "print(data_fail.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ze_Hzl1-a_c0"
      },
      "outputs": [],
      "source": [
        "# 공정 상태 숫자로 분류\n",
        "data_pass = machining_process(data_pass)\n",
        "data_pass_half = machining_process(data_pass_half)\n",
        "data_fail = machining_process(data_fail)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIHhk-JLbNjs",
        "outputId": "78dd792e-4620-4d96-d619-6c410e956e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[202.0 4.0 4.0 ... 0 50 8]\n",
            " [202.0 -6.8 -346.0 ... 4 50 0]\n",
            " [200.0 -13.8 -2.25 ... 7 50 0]\n",
            " ...\n",
            " [155.0 9.875 -64.6 ... 0 50 8]\n",
            " [155.5 9.95 -52.125 ... 0 50 8]\n",
            " [156.0 10.1 76.125 ... 0 50 8]]\n",
            "(18806, 48)\n",
            "(13242, 48)\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋 구성 -> 라벨링 (data_pass:0, data_pass_half,data_fail:1)\n",
        "data01 = data_pass[0:3228+6175,:] # 양품과 불량품 학습을 균형있게 해야 예측을 학습이 잘됨\n",
        "data02 = data_pass_half[0:6175,:]\n",
        "data03 = data_fail[0:3228,:]\n",
        "\n",
        "data = np.concatenate((data01,data02),axis = 0);\n",
        "data = np.concatenate((data,data03),axis = 0); # 학습할 데이터: 불량품과 양품이 균일한 분포로 들어간 데이터셋\n",
        "data_all = data_pass[3228+6175:22645,:] # 학습하고 남은 pass 데이터를 평가 데이터로 쓰기 위해 만들어놓음\n",
        "\n",
        "print(data)\n",
        "print(data.shape) # 학습 데이터 \n",
        "print(data_all.shape) # 평가 데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBgkc5JUhL1F"
      },
      "outputs": [],
      "source": [
        "sc = MinMaxScaler()\n",
        "X_train = sc.fit_transform(data) # 학습할 데이터셋에 대해서 각 열의 데이터의 최소값과 최대값을 0,1로 두고 나머지 값들을 그 사이 값들로 재조정\n",
        "X_train = np.array(X_train)\n",
        "X_test = sc.fit_transform(data_all) # 평가할 데이터셋에 대해서 각 열의 데이터의 최소값과 최대값을 0,1로 두고 나머지 값들을 그 사이 값들로 재조정\n",
        "X_test = np.array(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U30YQ0wgh-tV"
      },
      "source": [
        "# 데이터 라벨링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIk7lmsbh9DH",
        "outputId": "a23cd2b8-3efd-448c-d5d9-4e321d786bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "Y_train = np.zeros((len(X_train),1),dtype='int')\n",
        "Y_test = np.zeros((len(X_test),1),dtype='int')\n",
        "l = int(Y_train.shape[0]/2)\n",
        "\n",
        "Y_train[0:l,:] = 0\n",
        "Y_train[l:l*2,:] = 1\n",
        "\n",
        "print(Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftkDC2PTnWRt"
      },
      "source": [
        "# 학습/검증/평가 데이터 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK2yL1yqnZDE"
      },
      "outputs": [],
      "source": [
        "# 학습 시작전에 학습 데이터를 9:1로 학습데이터와 검증데이터로 랜덤하게 나눠 학습한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jQ5XrJpoL5O"
      },
      "source": [
        "# AI 모델 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cHeYNDFoNZJ"
      },
      "outputs": [],
      "source": [
        "nb_classes = 2      # 학습 데이터셋의 라벨 종류의 개수\n",
        "batch_size = 1024   # 학습 데이터셋 배치 사이즈\n",
        "epochs = 300 # 한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것을 말함. 즉, 전체 데이터 셋에 대해 한 번 학습을 완료한 상태\n",
        "lr = 1e-4\n",
        "# https://jonhyuk0922.tistory.com/129\n",
        "# 그림으로 설명하기 사진 첨부와 값의 변화에 따라 어떤 영향 미치는지 설명"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxZgAThYo2Sr",
        "outputId": "0f44ed44-151f-4953-83cb-32ec13ff6fef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18806, 48)\n",
            "(13242, 48)\n",
            "(18806, 2)\n",
            "(13242, 2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "Y_train = np_utils.to_categorical(Y_train, nb_classes) # 라벨 데이터를 원 핫 인코딩으로 원핫벡터로 표현 \n",
        "Y_test = np_utils.to_categorical(Y_test, nb_classes)   # 0 -> [1,0]  1 -> [0,1]\n",
        "                                                       # 차원 맞추기 : 데이터 학습 완료하고 양품확률, 불량품 확률 2차원으로 출력, 손실 값 확인할 때 cross entropy 차원 수 2차원 맞춰주기 위해 사용\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n",
        "Y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKs8Xvha4aYx"
      },
      "source": [
        "# 모델 디자인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM15cXQ94qXG"
      },
      "source": [
        "https://www.tensorflow.org/guide/keras/sequential_model?hl=ko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_te0Gb2N38fi",
        "outputId": "c5289df3-bbd6-4bee-c6ff-bdc713a36515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 128)               6272      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 598,018\n",
            "Trainable params: 598,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            ".............................model is defined.............................\n"
          ]
        }
      ],
      "source": [
        "model = Sequential() #  모델은 계층을 선형으로 쌓은 것으로 각 레이어에 정확히 하나의 입력 텐서와 하나의 출력 텐서가 있는 일반 레이어 스택\n",
        "model.add(Dense(128, activation= 'relu', input_dim = 48)) # 노드 수는 128개, 활성함수는 relu, input 차원은 독립변수 개수인 48개  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu')) # 깊이가 깊어서 sigmoid를 쓰면 0에 수렴할 확률이 있기 때문에 relu 활성함수를 사용하는 것 \n",
        "model.add(Dropout(0.5))                  # 처음에 지역최소값에 빠져서 \n",
        "model.add(Dense(512, activation='relu')) # relu 사용 이유와 back-propagation 개념, 언제하는지\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes, activation='sigmoid')) # 양품 확률, 불량품 확률 출력하기 위해 확률로 노드2개 -> dense =2 \n",
        "\n",
        "model_checkpoint = ModelCheckpoint('weight_CNC_binary.mat', monitor='val_acc',save_best_only=True) # val_acc가 개선되었을 때, 가장 best인 가중치 값을 저장 - 매 에폭 종료시 검증 데이터에 대한 정확도를 확인하고 가장 좋은 값을 기록하였을 때의 가중치를 저장한다\n",
        "opt=Adam(lr)           # 옵티마이저는 빠르고 정확하게 학습하기 위해 방향 설정해주는 건데 Adam에서는 기울기 값과 기울기의 제곱값의 지수이동평균을 활용하여 step변화량을 조절한다.\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer=opt,loss='binary_crossentropy', # 학습방식 설정 optimizer 은 아담, loss는 이진크로스엔트로피 평가 지표는 정확성\n",
        "              metrics=['accuracy'])                     # 손실 함수는 데이터를 토대로 산출한 모델의 예측 값과 실제 값과의 차이를 표현하는 지표 -> 모델의 학습 진행상황을 판단\n",
        "history = History() # 학습 과정 동안의 정확도와 손실도 등을 기록\n",
        "print('.............................model is defined.............................')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEAQBokTwqiO"
      },
      "source": [
        "# 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boHdt9nPwrYn",
        "outputId": "4c4acd56-fb09-4b99-e3ec-b705a12242e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 16925 samples, validate on 1881 samples\n",
            "Epoch 1/300\n",
            " - 1s - loss: 0.6984 - acc: 0.5223 - val_loss: 0.7177 - val_acc: 0.0125\n",
            "Epoch 2/300\n",
            " - 0s - loss: 0.6922 - acc: 0.5383 - val_loss: 0.7159 - val_acc: 0.0013\n",
            "Epoch 3/300\n",
            " - 0s - loss: 0.6900 - acc: 0.5405 - val_loss: 0.7157 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            " - 0s - loss: 0.6869 - acc: 0.5464 - val_loss: 0.7168 - val_acc: 0.0011\n",
            "Epoch 5/300\n",
            " - 0s - loss: 0.6844 - acc: 0.5503 - val_loss: 0.7207 - val_acc: 0.0218\n",
            "Epoch 6/300\n",
            " - 0s - loss: 0.6789 - acc: 0.5560 - val_loss: 0.7293 - val_acc: 0.1502\n",
            "Epoch 7/300\n",
            " - 0s - loss: 0.6724 - acc: 0.5626 - val_loss: 0.7348 - val_acc: 0.4258\n",
            "Epoch 8/300\n",
            " - 0s - loss: 0.6655 - acc: 0.5700 - val_loss: 0.7378 - val_acc: 0.5362\n",
            "Epoch 9/300\n",
            " - 0s - loss: 0.6565 - acc: 0.5816 - val_loss: 0.7312 - val_acc: 0.6457\n",
            "Epoch 10/300\n",
            " - 0s - loss: 0.6404 - acc: 0.6088 - val_loss: 0.7083 - val_acc: 0.7262\n",
            "Epoch 11/300\n",
            " - 0s - loss: 0.6284 - acc: 0.6362 - val_loss: 0.6632 - val_acc: 0.8187\n",
            "Epoch 12/300\n",
            " - 0s - loss: 0.6114 - acc: 0.6625 - val_loss: 0.6150 - val_acc: 0.8817\n",
            "Epoch 13/300\n",
            " - 0s - loss: 0.5964 - acc: 0.6755 - val_loss: 0.5666 - val_acc: 0.9192\n",
            "Epoch 14/300\n",
            " - 0s - loss: 0.5773 - acc: 0.6963 - val_loss: 0.5404 - val_acc: 0.9519\n",
            "Epoch 15/300\n",
            " - 0s - loss: 0.5657 - acc: 0.7040 - val_loss: 0.5199 - val_acc: 0.9755\n",
            "Epoch 16/300\n",
            " - 0s - loss: 0.5469 - acc: 0.7162 - val_loss: 0.4919 - val_acc: 0.9894\n",
            "Epoch 17/300\n",
            " - 0s - loss: 0.5268 - acc: 0.7360 - val_loss: 0.4679 - val_acc: 0.9947\n",
            "Epoch 18/300\n",
            " - 0s - loss: 0.5077 - acc: 0.7498 - val_loss: 0.4474 - val_acc: 0.9979\n",
            "Epoch 19/300\n",
            " - 0s - loss: 0.4928 - acc: 0.7571 - val_loss: 0.4256 - val_acc: 0.9995\n",
            "Epoch 20/300\n",
            " - 0s - loss: 0.4799 - acc: 0.7703 - val_loss: 0.4096 - val_acc: 0.9995\n",
            "Epoch 21/300\n",
            " - 0s - loss: 0.4646 - acc: 0.7826 - val_loss: 0.3890 - val_acc: 0.9995\n",
            "Epoch 22/300\n",
            " - 0s - loss: 0.4623 - acc: 0.7853 - val_loss: 0.3804 - val_acc: 0.9995\n",
            "Epoch 23/300\n",
            " - 0s - loss: 0.4482 - acc: 0.7907 - val_loss: 0.3605 - val_acc: 1.0000\n",
            "Epoch 24/300\n",
            " - 0s - loss: 0.4405 - acc: 0.7973 - val_loss: 0.3501 - val_acc: 1.0000\n",
            "Epoch 25/300\n",
            " - 0s - loss: 0.4261 - acc: 0.8131 - val_loss: 0.3325 - val_acc: 1.0000\n",
            "Epoch 26/300\n",
            " - 0s - loss: 0.4219 - acc: 0.8130 - val_loss: 0.3179 - val_acc: 1.0000\n",
            "Epoch 27/300\n",
            " - 0s - loss: 0.4138 - acc: 0.8183 - val_loss: 0.2953 - val_acc: 1.0000\n",
            "Epoch 28/300\n",
            " - 0s - loss: 0.4012 - acc: 0.8282 - val_loss: 0.2818 - val_acc: 1.0000\n",
            "Epoch 29/300\n",
            " - 0s - loss: 0.3979 - acc: 0.8286 - val_loss: 0.2830 - val_acc: 0.9997\n",
            "Epoch 30/300\n",
            " - 0s - loss: 0.3918 - acc: 0.8324 - val_loss: 0.2644 - val_acc: 1.0000\n",
            "Epoch 31/300\n",
            " - 0s - loss: 0.3785 - acc: 0.8425 - val_loss: 0.2487 - val_acc: 0.9995\n",
            "Epoch 32/300\n",
            " - 0s - loss: 0.3758 - acc: 0.8426 - val_loss: 0.2407 - val_acc: 0.9995\n",
            "Epoch 33/300\n",
            " - 0s - loss: 0.3612 - acc: 0.8534 - val_loss: 0.2208 - val_acc: 0.9995\n",
            "Epoch 34/300\n",
            " - 0s - loss: 0.3594 - acc: 0.8516 - val_loss: 0.2215 - val_acc: 0.9989\n",
            "Epoch 35/300\n",
            " - 0s - loss: 0.3454 - acc: 0.8590 - val_loss: 0.1941 - val_acc: 0.9989\n",
            "Epoch 36/300\n",
            " - 0s - loss: 0.3455 - acc: 0.8614 - val_loss: 0.1952 - val_acc: 0.9989\n",
            "Epoch 37/300\n",
            " - 0s - loss: 0.3454 - acc: 0.8624 - val_loss: 0.1862 - val_acc: 0.9989\n",
            "Epoch 38/300\n",
            " - 0s - loss: 0.3348 - acc: 0.8671 - val_loss: 0.1818 - val_acc: 0.9989\n",
            "Epoch 39/300\n",
            " - 0s - loss: 0.3223 - acc: 0.8675 - val_loss: 0.1837 - val_acc: 0.9883\n",
            "Epoch 40/300\n",
            " - 0s - loss: 0.3160 - acc: 0.8752 - val_loss: 0.1644 - val_acc: 0.9960\n",
            "Epoch 41/300\n",
            " - 0s - loss: 0.3090 - acc: 0.8767 - val_loss: 0.1511 - val_acc: 0.9963\n",
            "Epoch 42/300\n",
            " - 0s - loss: 0.3106 - acc: 0.8763 - val_loss: 0.1814 - val_acc: 0.9165\n",
            "Epoch 43/300\n",
            " - 0s - loss: 0.3050 - acc: 0.8778 - val_loss: 0.1598 - val_acc: 0.9503\n",
            "Epoch 44/300\n",
            " - 0s - loss: 0.2964 - acc: 0.8825 - val_loss: 0.1672 - val_acc: 0.9144\n",
            "Epoch 45/300\n",
            " - 0s - loss: 0.2950 - acc: 0.8830 - val_loss: 0.1501 - val_acc: 0.9261\n",
            "Epoch 46/300\n",
            " - 0s - loss: 0.2923 - acc: 0.8850 - val_loss: 0.1655 - val_acc: 0.9117\n",
            "Epoch 47/300\n",
            " - 0s - loss: 0.2868 - acc: 0.8863 - val_loss: 0.1663 - val_acc: 0.9117\n",
            "Epoch 48/300\n",
            " - 0s - loss: 0.2747 - acc: 0.8924 - val_loss: 0.1625 - val_acc: 0.9117\n",
            "Epoch 49/300\n",
            " - 0s - loss: 0.2752 - acc: 0.8933 - val_loss: 0.1913 - val_acc: 0.9080\n",
            "Epoch 50/300\n",
            " - 0s - loss: 0.2721 - acc: 0.8950 - val_loss: 0.1754 - val_acc: 0.9112\n",
            "Epoch 51/300\n",
            " - 0s - loss: 0.2698 - acc: 0.8968 - val_loss: 0.1686 - val_acc: 0.9117\n",
            "Epoch 52/300\n",
            " - 0s - loss: 0.2634 - acc: 0.8980 - val_loss: 0.1932 - val_acc: 0.9054\n",
            "Epoch 53/300\n",
            " - 0s - loss: 0.2572 - acc: 0.8984 - val_loss: 0.1907 - val_acc: 0.9038\n",
            "Epoch 54/300\n",
            " - 0s - loss: 0.2554 - acc: 0.8994 - val_loss: 0.1830 - val_acc: 0.9075\n",
            "Epoch 55/300\n",
            " - 0s - loss: 0.2505 - acc: 0.9015 - val_loss: 0.1869 - val_acc: 0.9043\n",
            "Epoch 56/300\n",
            " - 0s - loss: 0.2504 - acc: 0.9011 - val_loss: 0.2120 - val_acc: 0.8915\n",
            "Epoch 57/300\n",
            " - 0s - loss: 0.2468 - acc: 0.9044 - val_loss: 0.2401 - val_acc: 0.8682\n",
            "Epoch 58/300\n",
            " - 0s - loss: 0.2388 - acc: 0.9069 - val_loss: 0.2292 - val_acc: 0.8844\n",
            "Epoch 59/300\n",
            " - 0s - loss: 0.2387 - acc: 0.9065 - val_loss: 0.2617 - val_acc: 0.8533\n",
            "Epoch 60/300\n",
            " - 0s - loss: 0.2377 - acc: 0.9081 - val_loss: 0.2682 - val_acc: 0.8442\n",
            "Epoch 61/300\n",
            " - 0s - loss: 0.2371 - acc: 0.9086 - val_loss: 0.2663 - val_acc: 0.8432\n",
            "Epoch 62/300\n",
            " - 0s - loss: 0.2288 - acc: 0.9126 - val_loss: 0.3069 - val_acc: 0.8352\n",
            "Epoch 63/300\n",
            " - 0s - loss: 0.2269 - acc: 0.9113 - val_loss: 0.2271 - val_acc: 0.8806\n",
            "Epoch 64/300\n",
            " - 0s - loss: 0.2268 - acc: 0.9116 - val_loss: 0.2855 - val_acc: 0.8410\n",
            "Epoch 65/300\n",
            " - 0s - loss: 0.2225 - acc: 0.9136 - val_loss: 0.2482 - val_acc: 0.8589\n",
            "Epoch 66/300\n",
            " - 0s - loss: 0.2201 - acc: 0.9149 - val_loss: 0.2769 - val_acc: 0.8437\n",
            "Epoch 67/300\n",
            " - 0s - loss: 0.2165 - acc: 0.9150 - val_loss: 0.3006 - val_acc: 0.8421\n",
            "Epoch 68/300\n",
            " - 0s - loss: 0.2213 - acc: 0.9130 - val_loss: 0.3039 - val_acc: 0.8347\n",
            "Epoch 69/300\n",
            " - 0s - loss: 0.2163 - acc: 0.9143 - val_loss: 0.3225 - val_acc: 0.8009\n",
            "Epoch 70/300\n",
            " - 0s - loss: 0.2127 - acc: 0.9168 - val_loss: 0.3402 - val_acc: 0.7911\n",
            "Epoch 71/300\n",
            " - 0s - loss: 0.2102 - acc: 0.9170 - val_loss: 0.3670 - val_acc: 0.7900\n",
            "Epoch 72/300\n",
            " - 0s - loss: 0.2165 - acc: 0.9151 - val_loss: 0.3281 - val_acc: 0.7919\n",
            "Epoch 73/300\n",
            " - 0s - loss: 0.2064 - acc: 0.9181 - val_loss: 0.3507 - val_acc: 0.7889\n",
            "Epoch 74/300\n",
            " - 0s - loss: 0.2012 - acc: 0.9231 - val_loss: 0.3548 - val_acc: 0.7895\n",
            "Epoch 75/300\n",
            " - 0s - loss: 0.2039 - acc: 0.9219 - val_loss: 0.3847 - val_acc: 0.7884\n",
            "Epoch 76/300\n",
            " - 0s - loss: 0.1948 - acc: 0.9215 - val_loss: 0.3721 - val_acc: 0.7895\n",
            "Epoch 77/300\n",
            " - 0s - loss: 0.1985 - acc: 0.9225 - val_loss: 0.4158 - val_acc: 0.7873\n",
            "Epoch 78/300\n",
            " - 0s - loss: 0.1951 - acc: 0.9231 - val_loss: 0.3721 - val_acc: 0.7900\n",
            "Epoch 79/300\n",
            " - 0s - loss: 0.1919 - acc: 0.9250 - val_loss: 0.3645 - val_acc: 0.7900\n",
            "Epoch 80/300\n",
            " - 0s - loss: 0.1945 - acc: 0.9224 - val_loss: 0.3871 - val_acc: 0.7879\n",
            "Epoch 81/300\n",
            " - 0s - loss: 0.1873 - acc: 0.9284 - val_loss: 0.4219 - val_acc: 0.7868\n",
            "Epoch 82/300\n",
            " - 0s - loss: 0.1907 - acc: 0.9244 - val_loss: 0.4083 - val_acc: 0.7873\n",
            "Epoch 83/300\n",
            " - 0s - loss: 0.1873 - acc: 0.9259 - val_loss: 0.3984 - val_acc: 0.7876\n",
            "Epoch 84/300\n",
            " - 0s - loss: 0.1870 - acc: 0.9264 - val_loss: 0.4350 - val_acc: 0.7831\n",
            "Epoch 85/300\n",
            " - 0s - loss: 0.1845 - acc: 0.9277 - val_loss: 0.4542 - val_acc: 0.7807\n",
            "Epoch 86/300\n",
            " - 0s - loss: 0.1815 - acc: 0.9272 - val_loss: 0.4482 - val_acc: 0.7820\n",
            "Epoch 87/300\n",
            " - 0s - loss: 0.1809 - acc: 0.9275 - val_loss: 0.4524 - val_acc: 0.7826\n",
            "Epoch 88/300\n",
            " - 0s - loss: 0.1801 - acc: 0.9298 - val_loss: 0.4805 - val_acc: 0.7794\n",
            "Epoch 89/300\n",
            " - 0s - loss: 0.1809 - acc: 0.9290 - val_loss: 0.4194 - val_acc: 0.7847\n",
            "Epoch 90/300\n",
            " - 0s - loss: 0.1780 - acc: 0.9297 - val_loss: 0.4743 - val_acc: 0.7794\n",
            "Epoch 91/300\n",
            " - 0s - loss: 0.1789 - acc: 0.9310 - val_loss: 0.4607 - val_acc: 0.7810\n",
            "Epoch 92/300\n",
            " - 0s - loss: 0.1737 - acc: 0.9304 - val_loss: 0.5047 - val_acc: 0.7788\n",
            "Epoch 93/300\n",
            " - 0s - loss: 0.1690 - acc: 0.9318 - val_loss: 0.4919 - val_acc: 0.7799\n",
            "Epoch 94/300\n",
            " - 0s - loss: 0.1707 - acc: 0.9323 - val_loss: 0.5146 - val_acc: 0.7786\n",
            "Epoch 95/300\n",
            " - 0s - loss: 0.1729 - acc: 0.9299 - val_loss: 0.5007 - val_acc: 0.7778\n",
            "Epoch 96/300\n",
            " - 0s - loss: 0.1724 - acc: 0.9314 - val_loss: 0.4782 - val_acc: 0.7788\n",
            "Epoch 97/300\n",
            " - 0s - loss: 0.1724 - acc: 0.9325 - val_loss: 0.4807 - val_acc: 0.7804\n",
            "Epoch 98/300\n",
            " - 0s - loss: 0.1633 - acc: 0.9338 - val_loss: 0.5176 - val_acc: 0.7788\n",
            "Epoch 99/300\n",
            " - 0s - loss: 0.1656 - acc: 0.9319 - val_loss: 0.5282 - val_acc: 0.7788\n",
            "Epoch 100/300\n",
            " - 0s - loss: 0.1634 - acc: 0.9362 - val_loss: 0.5295 - val_acc: 0.7791\n",
            "Epoch 101/300\n",
            " - 0s - loss: 0.1618 - acc: 0.9318 - val_loss: 0.4976 - val_acc: 0.7820\n",
            "Epoch 102/300\n",
            " - 0s - loss: 0.1632 - acc: 0.9346 - val_loss: 0.5273 - val_acc: 0.7786\n",
            "Epoch 103/300\n",
            " - 0s - loss: 0.1589 - acc: 0.9360 - val_loss: 0.5769 - val_acc: 0.7757\n",
            "Epoch 104/300\n",
            " - 0s - loss: 0.1593 - acc: 0.9332 - val_loss: 0.5487 - val_acc: 0.7794\n",
            "Epoch 105/300\n",
            " - 0s - loss: 0.1631 - acc: 0.9335 - val_loss: 0.5491 - val_acc: 0.7767\n",
            "Epoch 106/300\n",
            " - 0s - loss: 0.1579 - acc: 0.9369 - val_loss: 0.5246 - val_acc: 0.7788\n",
            "Epoch 107/300\n",
            " - 0s - loss: 0.1560 - acc: 0.9370 - val_loss: 0.5413 - val_acc: 0.7783\n",
            "Epoch 108/300\n",
            " - 0s - loss: 0.1603 - acc: 0.9366 - val_loss: 0.5632 - val_acc: 0.7778\n",
            "Epoch 109/300\n",
            " - 0s - loss: 0.1549 - acc: 0.9365 - val_loss: 0.6010 - val_acc: 0.7772\n",
            "Epoch 110/300\n",
            " - 0s - loss: 0.1530 - acc: 0.9384 - val_loss: 0.5847 - val_acc: 0.7772\n",
            "Epoch 111/300\n",
            " - 0s - loss: 0.1548 - acc: 0.9360 - val_loss: 0.5773 - val_acc: 0.7767\n",
            "Epoch 112/300\n",
            " - 0s - loss: 0.1491 - acc: 0.9379 - val_loss: 0.6107 - val_acc: 0.7757\n",
            "Epoch 113/300\n",
            " - 0s - loss: 0.1481 - acc: 0.9373 - val_loss: 0.5540 - val_acc: 0.7815\n",
            "Epoch 114/300\n",
            " - 0s - loss: 0.1491 - acc: 0.9379 - val_loss: 0.5992 - val_acc: 0.7778\n",
            "Epoch 115/300\n",
            " - 0s - loss: 0.1547 - acc: 0.9359 - val_loss: 0.5873 - val_acc: 0.7772\n",
            "Epoch 116/300\n",
            " - 0s - loss: 0.1472 - acc: 0.9407 - val_loss: 0.6320 - val_acc: 0.7757\n",
            "Epoch 117/300\n",
            " - 0s - loss: 0.1511 - acc: 0.9388 - val_loss: 0.6320 - val_acc: 0.7746\n",
            "Epoch 118/300\n",
            " - 0s - loss: 0.1497 - acc: 0.9379 - val_loss: 0.5814 - val_acc: 0.7788\n",
            "Epoch 119/300\n",
            " - 0s - loss: 0.1473 - acc: 0.9401 - val_loss: 0.6539 - val_acc: 0.7757\n",
            "Epoch 120/300\n",
            " - 0s - loss: 0.1418 - acc: 0.9412 - val_loss: 0.6580 - val_acc: 0.7751\n",
            "Epoch 121/300\n",
            " - 0s - loss: 0.1452 - acc: 0.9404 - val_loss: 0.6197 - val_acc: 0.7767\n",
            "Epoch 122/300\n",
            " - 0s - loss: 0.1424 - acc: 0.9404 - val_loss: 0.6337 - val_acc: 0.7762\n",
            "Epoch 123/300\n",
            " - 0s - loss: 0.1390 - acc: 0.9424 - val_loss: 0.6476 - val_acc: 0.7757\n",
            "Epoch 124/300\n",
            " - 0s - loss: 0.1405 - acc: 0.9410 - val_loss: 0.6526 - val_acc: 0.7746\n",
            "Epoch 125/300\n",
            " - 0s - loss: 0.1399 - acc: 0.9418 - val_loss: 0.6718 - val_acc: 0.7751\n",
            "Epoch 126/300\n",
            " - 0s - loss: 0.1429 - acc: 0.9422 - val_loss: 0.6196 - val_acc: 0.7780\n",
            "Epoch 127/300\n",
            " - 0s - loss: 0.1418 - acc: 0.9413 - val_loss: 0.7132 - val_acc: 0.7751\n",
            "Epoch 128/300\n",
            " - 0s - loss: 0.1392 - acc: 0.9424 - val_loss: 0.6927 - val_acc: 0.7759\n",
            "Epoch 129/300\n",
            " - 0s - loss: 0.1415 - acc: 0.9416 - val_loss: 0.6457 - val_acc: 0.7762\n",
            "Epoch 130/300\n",
            " - 0s - loss: 0.1357 - acc: 0.9431 - val_loss: 0.6505 - val_acc: 0.7762\n",
            "Epoch 131/300\n",
            " - 0s - loss: 0.1371 - acc: 0.9438 - val_loss: 0.6900 - val_acc: 0.7762\n",
            "Epoch 132/300\n",
            " - 0s - loss: 0.1365 - acc: 0.9435 - val_loss: 0.7158 - val_acc: 0.7757\n",
            "Epoch 133/300\n",
            " - 0s - loss: 0.1347 - acc: 0.9430 - val_loss: 0.7242 - val_acc: 0.7762\n",
            "Epoch 134/300\n",
            " - 0s - loss: 0.1336 - acc: 0.9448 - val_loss: 0.7463 - val_acc: 0.7746\n",
            "Epoch 135/300\n",
            " - 0s - loss: 0.1356 - acc: 0.9428 - val_loss: 0.7037 - val_acc: 0.7746\n",
            "Epoch 136/300\n",
            " - 0s - loss: 0.1352 - acc: 0.9433 - val_loss: 0.7109 - val_acc: 0.7757\n",
            "Epoch 137/300\n",
            " - 0s - loss: 0.1310 - acc: 0.9456 - val_loss: 0.7254 - val_acc: 0.7762\n",
            "Epoch 138/300\n",
            " - 0s - loss: 0.1308 - acc: 0.9453 - val_loss: 0.7566 - val_acc: 0.7746\n",
            "Epoch 139/300\n",
            " - 0s - loss: 0.1315 - acc: 0.9445 - val_loss: 0.7688 - val_acc: 0.7746\n",
            "Epoch 140/300\n",
            " - 0s - loss: 0.1299 - acc: 0.9448 - val_loss: 0.7015 - val_acc: 0.7788\n",
            "Epoch 141/300\n",
            " - 0s - loss: 0.1346 - acc: 0.9445 - val_loss: 0.6916 - val_acc: 0.7762\n",
            "Epoch 142/300\n",
            " - 0s - loss: 0.1287 - acc: 0.9454 - val_loss: 0.7478 - val_acc: 0.7767\n",
            "Epoch 143/300\n",
            " - 0s - loss: 0.1348 - acc: 0.9437 - val_loss: 0.7598 - val_acc: 0.7735\n",
            "Epoch 144/300\n",
            " - 0s - loss: 0.1277 - acc: 0.9460 - val_loss: 0.7468 - val_acc: 0.7751\n",
            "Epoch 145/300\n",
            " - 0s - loss: 0.1292 - acc: 0.9454 - val_loss: 0.8058 - val_acc: 0.7735\n",
            "Epoch 146/300\n",
            " - 0s - loss: 0.1292 - acc: 0.9445 - val_loss: 0.6939 - val_acc: 0.7783\n",
            "Epoch 147/300\n",
            " - 0s - loss: 0.1256 - acc: 0.9467 - val_loss: 0.7689 - val_acc: 0.7741\n",
            "Epoch 148/300\n",
            " - 0s - loss: 0.1262 - acc: 0.9461 - val_loss: 0.7673 - val_acc: 0.7751\n",
            "Epoch 149/300\n",
            " - 0s - loss: 0.1261 - acc: 0.9477 - val_loss: 0.7813 - val_acc: 0.7757\n",
            "Epoch 150/300\n",
            " - 0s - loss: 0.1232 - acc: 0.9493 - val_loss: 0.8117 - val_acc: 0.7759\n",
            "Epoch 151/300\n",
            " - 0s - loss: 0.1257 - acc: 0.9464 - val_loss: 0.8029 - val_acc: 0.7751\n",
            "Epoch 152/300\n",
            " - 0s - loss: 0.1180 - acc: 0.9499 - val_loss: 0.8451 - val_acc: 0.7746\n",
            "Epoch 153/300\n",
            " - 0s - loss: 0.1254 - acc: 0.9479 - val_loss: 0.8460 - val_acc: 0.7749\n",
            "Epoch 154/300\n",
            " - 0s - loss: 0.1241 - acc: 0.9487 - val_loss: 0.8094 - val_acc: 0.7757\n",
            "Epoch 155/300\n",
            " - 0s - loss: 0.1244 - acc: 0.9471 - val_loss: 0.8127 - val_acc: 0.7751\n",
            "Epoch 156/300\n",
            " - 0s - loss: 0.1223 - acc: 0.9479 - val_loss: 0.8712 - val_acc: 0.7741\n",
            "Epoch 157/300\n",
            " - 0s - loss: 0.1202 - acc: 0.9510 - val_loss: 0.8161 - val_acc: 0.7757\n",
            "Epoch 158/300\n",
            " - 0s - loss: 0.1248 - acc: 0.9464 - val_loss: 0.8191 - val_acc: 0.7757\n",
            "Epoch 159/300\n",
            " - 0s - loss: 0.1233 - acc: 0.9482 - val_loss: 0.7974 - val_acc: 0.7746\n",
            "Epoch 160/300\n",
            " - 0s - loss: 0.1207 - acc: 0.9496 - val_loss: 0.8126 - val_acc: 0.7751\n",
            "Epoch 161/300\n",
            " - 0s - loss: 0.1186 - acc: 0.9486 - val_loss: 0.8137 - val_acc: 0.7751\n",
            "Epoch 162/300\n",
            " - 0s - loss: 0.1213 - acc: 0.9480 - val_loss: 0.8447 - val_acc: 0.7741\n",
            "Epoch 163/300\n",
            " - 0s - loss: 0.1174 - acc: 0.9491 - val_loss: 0.8121 - val_acc: 0.7757\n",
            "Epoch 164/300\n",
            " - 0s - loss: 0.1217 - acc: 0.9493 - val_loss: 0.8473 - val_acc: 0.7751\n",
            "Epoch 165/300\n",
            " - 0s - loss: 0.1240 - acc: 0.9480 - val_loss: 0.8932 - val_acc: 0.7735\n",
            "Epoch 166/300\n",
            " - 0s - loss: 0.1201 - acc: 0.9491 - val_loss: 0.8374 - val_acc: 0.7746\n",
            "Epoch 167/300\n",
            " - 0s - loss: 0.1133 - acc: 0.9495 - val_loss: 0.8671 - val_acc: 0.7741\n",
            "Epoch 168/300\n",
            " - 0s - loss: 0.1168 - acc: 0.9505 - val_loss: 0.8311 - val_acc: 0.7746\n",
            "Epoch 169/300\n",
            " - 0s - loss: 0.1165 - acc: 0.9516 - val_loss: 0.8765 - val_acc: 0.7741\n",
            "Epoch 170/300\n",
            " - 0s - loss: 0.1181 - acc: 0.9500 - val_loss: 0.8657 - val_acc: 0.7746\n",
            "Epoch 171/300\n",
            " - 0s - loss: 0.1120 - acc: 0.9533 - val_loss: 0.8982 - val_acc: 0.7746\n",
            "Epoch 172/300\n",
            " - 0s - loss: 0.1120 - acc: 0.9523 - val_loss: 0.9251 - val_acc: 0.7746\n",
            "Epoch 173/300\n",
            " - 0s - loss: 0.1109 - acc: 0.9523 - val_loss: 0.8934 - val_acc: 0.7746\n",
            "Epoch 174/300\n",
            " - 0s - loss: 0.1105 - acc: 0.9532 - val_loss: 0.9424 - val_acc: 0.7735\n",
            "Epoch 175/300\n",
            " - 0s - loss: 0.1132 - acc: 0.9505 - val_loss: 0.9208 - val_acc: 0.7730\n",
            "Epoch 176/300\n",
            " - 0s - loss: 0.1197 - acc: 0.9516 - val_loss: 0.9045 - val_acc: 0.7735\n",
            "Epoch 177/300\n",
            " - 0s - loss: 0.1126 - acc: 0.9525 - val_loss: 0.8853 - val_acc: 0.7735\n",
            "Epoch 178/300\n",
            " - 0s - loss: 0.1156 - acc: 0.9508 - val_loss: 0.9472 - val_acc: 0.7735\n",
            "Epoch 179/300\n",
            " - 0s - loss: 0.1142 - acc: 0.9519 - val_loss: 0.8661 - val_acc: 0.7746\n",
            "Epoch 180/300\n",
            " - 0s - loss: 0.1123 - acc: 0.9538 - val_loss: 0.9230 - val_acc: 0.7735\n",
            "Epoch 181/300\n",
            " - 0s - loss: 0.1098 - acc: 0.9532 - val_loss: 0.8634 - val_acc: 0.7746\n",
            "Epoch 182/300\n",
            " - 0s - loss: 0.1128 - acc: 0.9524 - val_loss: 0.9922 - val_acc: 0.7730\n",
            "Epoch 183/300\n",
            " - 0s - loss: 0.1101 - acc: 0.9534 - val_loss: 0.9110 - val_acc: 0.7741\n",
            "Epoch 184/300\n",
            " - 0s - loss: 0.1135 - acc: 0.9540 - val_loss: 0.9028 - val_acc: 0.7738\n",
            "Epoch 185/300\n",
            " - 0s - loss: 0.1099 - acc: 0.9521 - val_loss: 0.9017 - val_acc: 0.7730\n",
            "Epoch 186/300\n",
            " - 0s - loss: 0.1070 - acc: 0.9529 - val_loss: 0.9347 - val_acc: 0.7730\n",
            "Epoch 187/300\n",
            " - 0s - loss: 0.1094 - acc: 0.9523 - val_loss: 0.9564 - val_acc: 0.7735\n",
            "Epoch 188/300\n",
            " - 0s - loss: 0.1050 - acc: 0.9551 - val_loss: 0.9711 - val_acc: 0.7741\n",
            "Epoch 189/300\n",
            " - 0s - loss: 0.1116 - acc: 0.9518 - val_loss: 0.9750 - val_acc: 0.7738\n",
            "Epoch 190/300\n",
            " - 0s - loss: 0.1065 - acc: 0.9543 - val_loss: 0.9680 - val_acc: 0.7746\n",
            "Epoch 191/300\n",
            " - 0s - loss: 0.1038 - acc: 0.9559 - val_loss: 0.9867 - val_acc: 0.7746\n",
            "Epoch 192/300\n",
            " - 0s - loss: 0.1076 - acc: 0.9554 - val_loss: 0.9904 - val_acc: 0.7741\n",
            "Epoch 193/300\n",
            " - 0s - loss: 0.1006 - acc: 0.9552 - val_loss: 0.9286 - val_acc: 0.7762\n",
            "Epoch 194/300\n",
            " - 0s - loss: 0.1035 - acc: 0.9558 - val_loss: 1.0743 - val_acc: 0.7725\n",
            "Epoch 195/300\n",
            " - 0s - loss: 0.1008 - acc: 0.9570 - val_loss: 1.0329 - val_acc: 0.7725\n",
            "Epoch 196/300\n",
            " - 0s - loss: 0.1062 - acc: 0.9552 - val_loss: 1.0250 - val_acc: 0.7741\n",
            "Epoch 197/300\n",
            " - 0s - loss: 0.1055 - acc: 0.9555 - val_loss: 1.0151 - val_acc: 0.7741\n",
            "Epoch 198/300\n",
            " - 0s - loss: 0.1040 - acc: 0.9555 - val_loss: 1.0379 - val_acc: 0.7741\n",
            "Epoch 199/300\n",
            " - 0s - loss: 0.0986 - acc: 0.9586 - val_loss: 1.0899 - val_acc: 0.7738\n",
            "Epoch 200/300\n",
            " - 0s - loss: 0.1055 - acc: 0.9548 - val_loss: 1.0988 - val_acc: 0.7730\n",
            "Epoch 201/300\n",
            " - 0s - loss: 0.1036 - acc: 0.9560 - val_loss: 1.0163 - val_acc: 0.7730\n",
            "Epoch 202/300\n",
            " - 0s - loss: 0.1074 - acc: 0.9550 - val_loss: 1.0438 - val_acc: 0.7730\n",
            "Epoch 203/300\n",
            " - 0s - loss: 0.1040 - acc: 0.9568 - val_loss: 1.0261 - val_acc: 0.7730\n",
            "Epoch 204/300\n",
            " - 0s - loss: 0.1054 - acc: 0.9563 - val_loss: 1.0980 - val_acc: 0.7730\n",
            "Epoch 205/300\n",
            " - 0s - loss: 0.1007 - acc: 0.9572 - val_loss: 1.0851 - val_acc: 0.7735\n",
            "Epoch 206/300\n",
            " - 0s - loss: 0.1024 - acc: 0.9566 - val_loss: 1.1290 - val_acc: 0.7730\n",
            "Epoch 207/300\n",
            " - 0s - loss: 0.1004 - acc: 0.9567 - val_loss: 1.0778 - val_acc: 0.7730\n",
            "Epoch 208/300\n",
            " - 0s - loss: 0.0999 - acc: 0.9587 - val_loss: 1.0332 - val_acc: 0.7741\n",
            "Epoch 209/300\n",
            " - 0s - loss: 0.0986 - acc: 0.9578 - val_loss: 1.1820 - val_acc: 0.7725\n",
            "Epoch 210/300\n",
            " - 0s - loss: 0.1030 - acc: 0.9567 - val_loss: 1.1895 - val_acc: 0.7725\n",
            "Epoch 211/300\n",
            " - 0s - loss: 0.0993 - acc: 0.9580 - val_loss: 1.0507 - val_acc: 0.7730\n",
            "Epoch 212/300\n",
            " - 0s - loss: 0.1009 - acc: 0.9570 - val_loss: 1.1158 - val_acc: 0.7730\n",
            "Epoch 213/300\n",
            " - 0s - loss: 0.1025 - acc: 0.9557 - val_loss: 1.1093 - val_acc: 0.7730\n",
            "Epoch 214/300\n",
            " - 0s - loss: 0.0984 - acc: 0.9571 - val_loss: 1.1539 - val_acc: 0.7735\n",
            "Epoch 215/300\n",
            " - 0s - loss: 0.0983 - acc: 0.9575 - val_loss: 1.1577 - val_acc: 0.7725\n",
            "Epoch 216/300\n",
            " - 0s - loss: 0.1014 - acc: 0.9573 - val_loss: 1.0704 - val_acc: 0.7735\n",
            "Epoch 217/300\n",
            " - 0s - loss: 0.1018 - acc: 0.9569 - val_loss: 1.0798 - val_acc: 0.7730\n",
            "Epoch 218/300\n",
            " - 0s - loss: 0.1006 - acc: 0.9576 - val_loss: 1.1620 - val_acc: 0.7730\n",
            "Epoch 219/300\n",
            " - 0s - loss: 0.0992 - acc: 0.9574 - val_loss: 1.1484 - val_acc: 0.7722\n",
            "Epoch 220/300\n",
            " - 0s - loss: 0.0970 - acc: 0.9588 - val_loss: 1.1255 - val_acc: 0.7741\n",
            "Epoch 221/300\n",
            " - 0s - loss: 0.0970 - acc: 0.9593 - val_loss: 1.1681 - val_acc: 0.7730\n",
            "Epoch 222/300\n",
            " - 0s - loss: 0.1031 - acc: 0.9575 - val_loss: 1.0953 - val_acc: 0.7741\n",
            "Epoch 223/300\n",
            " - 0s - loss: 0.0969 - acc: 0.9583 - val_loss: 1.1198 - val_acc: 0.7725\n",
            "Epoch 224/300\n",
            " - 0s - loss: 0.1022 - acc: 0.9562 - val_loss: 1.1025 - val_acc: 0.7717\n",
            "Epoch 225/300\n",
            " - 0s - loss: 0.0989 - acc: 0.9582 - val_loss: 1.0901 - val_acc: 0.7735\n",
            "Epoch 226/300\n",
            " - 0s - loss: 0.0961 - acc: 0.9596 - val_loss: 1.1395 - val_acc: 0.7727\n",
            "Epoch 227/300\n",
            " - 0s - loss: 0.0937 - acc: 0.9585 - val_loss: 1.2032 - val_acc: 0.7714\n",
            "Epoch 228/300\n",
            " - 0s - loss: 0.0952 - acc: 0.9592 - val_loss: 1.1370 - val_acc: 0.7735\n",
            "Epoch 229/300\n",
            " - 0s - loss: 0.0952 - acc: 0.9585 - val_loss: 1.1093 - val_acc: 0.7722\n",
            "Epoch 230/300\n",
            " - 0s - loss: 0.0927 - acc: 0.9588 - val_loss: 1.1474 - val_acc: 0.7719\n",
            "Epoch 231/300\n",
            " - 0s - loss: 0.0978 - acc: 0.9587 - val_loss: 1.1699 - val_acc: 0.7719\n",
            "Epoch 232/300\n",
            " - 0s - loss: 0.0970 - acc: 0.9582 - val_loss: 1.1739 - val_acc: 0.7719\n",
            "Epoch 233/300\n",
            " - 0s - loss: 0.0922 - acc: 0.9597 - val_loss: 1.1931 - val_acc: 0.7709\n",
            "Epoch 234/300\n",
            " - 0s - loss: 0.0933 - acc: 0.9606 - val_loss: 1.1800 - val_acc: 0.7725\n",
            "Epoch 235/300\n",
            " - 0s - loss: 0.0927 - acc: 0.9618 - val_loss: 1.0808 - val_acc: 0.7730\n",
            "Epoch 236/300\n",
            " - 0s - loss: 0.0921 - acc: 0.9622 - val_loss: 1.2361 - val_acc: 0.7706\n",
            "Epoch 237/300\n",
            " - 0s - loss: 0.0917 - acc: 0.9620 - val_loss: 1.1271 - val_acc: 0.7730\n",
            "Epoch 238/300\n",
            " - 0s - loss: 0.0976 - acc: 0.9577 - val_loss: 1.1741 - val_acc: 0.7714\n",
            "Epoch 239/300\n",
            " - 0s - loss: 0.0894 - acc: 0.9600 - val_loss: 1.1753 - val_acc: 0.7735\n",
            "Epoch 240/300\n",
            " - 0s - loss: 0.0931 - acc: 0.9609 - val_loss: 1.1941 - val_acc: 0.7735\n",
            "Epoch 241/300\n",
            " - 0s - loss: 0.0900 - acc: 0.9600 - val_loss: 1.2393 - val_acc: 0.7730\n",
            "Epoch 242/300\n",
            " - 0s - loss: 0.0910 - acc: 0.9611 - val_loss: 1.2065 - val_acc: 0.7741\n",
            "Epoch 243/300\n",
            " - 0s - loss: 0.0906 - acc: 0.9609 - val_loss: 1.2027 - val_acc: 0.7735\n",
            "Epoch 244/300\n",
            " - 0s - loss: 0.0903 - acc: 0.9611 - val_loss: 1.2765 - val_acc: 0.7719\n",
            "Epoch 245/300\n",
            " - 0s - loss: 0.0864 - acc: 0.9620 - val_loss: 1.2371 - val_acc: 0.7730\n",
            "Epoch 246/300\n",
            " - 0s - loss: 0.0898 - acc: 0.9608 - val_loss: 1.2778 - val_acc: 0.7725\n",
            "Epoch 247/300\n",
            " - 0s - loss: 0.0879 - acc: 0.9617 - val_loss: 1.2593 - val_acc: 0.7730\n",
            "Epoch 248/300\n",
            " - 0s - loss: 0.0870 - acc: 0.9626 - val_loss: 1.3419 - val_acc: 0.7709\n",
            "Epoch 249/300\n",
            " - 0s - loss: 0.0926 - acc: 0.9600 - val_loss: 1.2964 - val_acc: 0.7735\n",
            "Epoch 250/300\n",
            " - 0s - loss: 0.0881 - acc: 0.9632 - val_loss: 1.3374 - val_acc: 0.7719\n",
            "Epoch 251/300\n",
            " - 0s - loss: 0.0922 - acc: 0.9606 - val_loss: 1.2594 - val_acc: 0.7730\n",
            "Epoch 252/300\n",
            " - 0s - loss: 0.0894 - acc: 0.9628 - val_loss: 1.3014 - val_acc: 0.7725\n",
            "Epoch 253/300\n",
            " - 0s - loss: 0.0880 - acc: 0.9633 - val_loss: 1.2967 - val_acc: 0.7730\n",
            "Epoch 254/300\n",
            " - 0s - loss: 0.0880 - acc: 0.9632 - val_loss: 1.3205 - val_acc: 0.7725\n",
            "Epoch 255/300\n",
            " - 0s - loss: 0.0870 - acc: 0.9626 - val_loss: 1.2833 - val_acc: 0.7709\n",
            "Epoch 256/300\n",
            " - 0s - loss: 0.0865 - acc: 0.9621 - val_loss: 1.3648 - val_acc: 0.7709\n",
            "Epoch 257/300\n",
            " - 0s - loss: 0.0858 - acc: 0.9636 - val_loss: 1.3511 - val_acc: 0.7719\n",
            "Epoch 258/300\n",
            " - 0s - loss: 0.0897 - acc: 0.9624 - val_loss: 1.3163 - val_acc: 0.7725\n",
            "Epoch 259/300\n",
            " - 0s - loss: 0.0882 - acc: 0.9629 - val_loss: 1.3175 - val_acc: 0.7725\n",
            "Epoch 260/300\n",
            " - 0s - loss: 0.0899 - acc: 0.9617 - val_loss: 1.3569 - val_acc: 0.7709\n",
            "Epoch 261/300\n",
            " - 0s - loss: 0.0821 - acc: 0.9645 - val_loss: 1.3383 - val_acc: 0.7714\n",
            "Epoch 262/300\n",
            " - 0s - loss: 0.0841 - acc: 0.9641 - val_loss: 1.3943 - val_acc: 0.7709\n",
            "Epoch 263/300\n",
            " - 0s - loss: 0.0862 - acc: 0.9639 - val_loss: 1.3379 - val_acc: 0.7725\n",
            "Epoch 264/300\n",
            " - 0s - loss: 0.0897 - acc: 0.9616 - val_loss: 1.4623 - val_acc: 0.7711\n",
            "Epoch 265/300\n",
            " - 0s - loss: 0.0851 - acc: 0.9647 - val_loss: 1.3907 - val_acc: 0.7730\n",
            "Epoch 266/300\n",
            " - 0s - loss: 0.0855 - acc: 0.9622 - val_loss: 1.3218 - val_acc: 0.7735\n",
            "Epoch 267/300\n",
            " - 0s - loss: 0.0868 - acc: 0.9630 - val_loss: 1.4263 - val_acc: 0.7719\n",
            "Epoch 268/300\n",
            " - 0s - loss: 0.0857 - acc: 0.9634 - val_loss: 1.3881 - val_acc: 0.7725\n",
            "Epoch 269/300\n",
            " - 0s - loss: 0.0848 - acc: 0.9635 - val_loss: 1.2923 - val_acc: 0.7727\n",
            "Epoch 270/300\n",
            " - 0s - loss: 0.0834 - acc: 0.9633 - val_loss: 1.4827 - val_acc: 0.7722\n",
            "Epoch 271/300\n",
            " - 0s - loss: 0.0799 - acc: 0.9651 - val_loss: 1.4470 - val_acc: 0.7730\n",
            "Epoch 272/300\n",
            " - 0s - loss: 0.0830 - acc: 0.9661 - val_loss: 1.4342 - val_acc: 0.7725\n",
            "Epoch 273/300\n",
            " - 0s - loss: 0.0847 - acc: 0.9632 - val_loss: 1.4392 - val_acc: 0.7725\n",
            "Epoch 274/300\n",
            " - 0s - loss: 0.0832 - acc: 0.9647 - val_loss: 1.4508 - val_acc: 0.7725\n",
            "Epoch 275/300\n",
            " - 0s - loss: 0.0866 - acc: 0.9621 - val_loss: 1.3750 - val_acc: 0.7730\n",
            "Epoch 276/300\n",
            " - 0s - loss: 0.0805 - acc: 0.9645 - val_loss: 1.4874 - val_acc: 0.7717\n",
            "Epoch 277/300\n",
            " - 0s - loss: 0.0839 - acc: 0.9632 - val_loss: 1.4312 - val_acc: 0.7730\n",
            "Epoch 278/300\n",
            " - 0s - loss: 0.0836 - acc: 0.9634 - val_loss: 1.4815 - val_acc: 0.7714\n",
            "Epoch 279/300\n",
            " - 0s - loss: 0.0837 - acc: 0.9640 - val_loss: 1.4492 - val_acc: 0.7717\n",
            "Epoch 280/300\n",
            " - 0s - loss: 0.0863 - acc: 0.9635 - val_loss: 1.4731 - val_acc: 0.7709\n",
            "Epoch 281/300\n",
            " - 0s - loss: 0.0854 - acc: 0.9621 - val_loss: 1.3336 - val_acc: 0.7719\n",
            "Epoch 282/300\n",
            " - 0s - loss: 0.0837 - acc: 0.9632 - val_loss: 1.3542 - val_acc: 0.7719\n",
            "Epoch 283/300\n",
            " - 0s - loss: 0.0826 - acc: 0.9634 - val_loss: 1.3970 - val_acc: 0.7714\n",
            "Epoch 284/300\n",
            " - 0s - loss: 0.0840 - acc: 0.9641 - val_loss: 1.3713 - val_acc: 0.7722\n",
            "Epoch 285/300\n",
            " - 0s - loss: 0.0792 - acc: 0.9671 - val_loss: 1.3488 - val_acc: 0.7722\n",
            "Epoch 286/300\n",
            " - 0s - loss: 0.0810 - acc: 0.9650 - val_loss: 1.3867 - val_acc: 0.7709\n",
            "Epoch 287/300\n",
            " - 0s - loss: 0.0802 - acc: 0.9646 - val_loss: 1.4842 - val_acc: 0.7717\n",
            "Epoch 288/300\n",
            " - 0s - loss: 0.0792 - acc: 0.9663 - val_loss: 1.4818 - val_acc: 0.7725\n",
            "Epoch 289/300\n",
            " - 0s - loss: 0.0791 - acc: 0.9652 - val_loss: 1.5060 - val_acc: 0.7709\n",
            "Epoch 290/300\n",
            " - 0s - loss: 0.0833 - acc: 0.9647 - val_loss: 1.4076 - val_acc: 0.7725\n",
            "Epoch 291/300\n",
            " - 0s - loss: 0.0794 - acc: 0.9652 - val_loss: 1.4514 - val_acc: 0.7725\n",
            "Epoch 292/300\n",
            " - 0s - loss: 0.0791 - acc: 0.9670 - val_loss: 1.4019 - val_acc: 0.7719\n",
            "Epoch 293/300\n",
            " - 0s - loss: 0.0801 - acc: 0.9638 - val_loss: 1.5069 - val_acc: 0.7719\n",
            "Epoch 294/300\n",
            " - 0s - loss: 0.0800 - acc: 0.9634 - val_loss: 1.4868 - val_acc: 0.7714\n",
            "Epoch 295/300\n",
            " - 0s - loss: 0.0814 - acc: 0.9660 - val_loss: 1.4393 - val_acc: 0.7717\n",
            "Epoch 296/300\n",
            " - 0s - loss: 0.0786 - acc: 0.9661 - val_loss: 1.3970 - val_acc: 0.7730\n",
            "Epoch 297/300\n",
            " - 0s - loss: 0.0790 - acc: 0.9669 - val_loss: 1.4271 - val_acc: 0.7714\n",
            "Epoch 298/300\n",
            " - 0s - loss: 0.0797 - acc: 0.9661 - val_loss: 1.5031 - val_acc: 0.7698\n",
            "Epoch 299/300\n",
            " - 0s - loss: 0.0807 - acc: 0.9663 - val_loss: 1.4324 - val_acc: 0.7719\n",
            "Epoch 300/300\n",
            " - 0s - loss: 0.0817 - acc: 0.9646 - val_loss: 1.5177 - val_acc: 0.7719\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, verbose =2, batch_size = batch_size, epochs= epochs, validation_split= 0.1, shuffle= True, callbacks = [history])\n",
        "# batchsize, epochs, validation_split, shuffle, history\n",
        "model.save_weights('weight_CNC_binary.mat')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFysMqknxZNa"
      },
      "source": [
        "# 결과 분석 및 해석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cRqrVnzxX2O",
        "outputId": "e9859822-7da1-49d9-cc1d-df74d1af72c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18806/18806 [==============================] - 1s 68us/step\n",
            "[0.19339895392987808, 0.9565298309050303]\n",
            "13242/13242 [==============================] - 1s 67us/step\n",
            "[0.9040804661578079, 0.9039420027186226]\n"
          ]
        }
      ],
      "source": [
        " # 데이터 셋 종류와 함께 설명\n",
        "loss_and_metrics = model.evaluate(X_train, Y_train, batch_size = 32)\n",
        "print(loss_and_metrics)\n",
        "loss_and_metrics2 = model.evaluate(X_test, Y_test, batch_size = 32)\n",
        "print(loss_and_metrics2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_bTwdR-xXw6",
        "outputId": "fab789a5-61b5-4e36-ab66-d2e6d71171e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbe9ccc0190>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['val_acc'])\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('Accuracy During Training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Validation Accuracy', 'Training Accuracy'])\n",
        " # 에폭 100 정도 부터 모델 훈련이 수렴하였다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbfR_Fe0y7l2",
        "outputId": "c7bc5161-b331-476f-bba4-03fd736131b1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Loss During Training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Validation Loss', 'Training Loss'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "67a67815f561936a237b330b4d705eb5c369a6c9583a9b9730f874040d906ccb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
